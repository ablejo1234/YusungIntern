{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Modeling"
      ],
      "metadata": {
        "id": "KM3wZDxogCV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1) 지수 생성"
      ],
      "metadata": {
        "id": "7rtdNd8XgM6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering"
      ],
      "metadata": {
        "id": "Uo3viFrVgPY1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrHc8oBVgBBA"
      },
      "outputs": [],
      "source": [
        "# pydeck 용 coordinates 만들어주기\n",
        "def multipolygon_to_coordinates(x):\n",
        "    lon, lat = x[0].exterior.xy\n",
        "    return [[x, y] for x, y in zip(lon, lat)]\n",
        "\n",
        "data32['coordinates'] = data32['geometry'].apply(multipolygon_to_coordinates)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pydeck 용 coordinates 만들어주기\n",
        "def multipolygon_to_coordinates(x):\n",
        "    lon, lat = x[0].exterior.xy\n",
        "    return [[x, y] for x, y in zip(lon, lat)]\n",
        "\n",
        "data32['coordinates'] = data32['geometry'].apply(multipolygon_to_coordinates)"
      ],
      "metadata": {
        "id": "kZ2dJow_gdfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##상권 클러스터링"
      ],
      "metadata": {
        "id": "PaxZgsiMgpWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HDBSCAN으로 상권 클러스터링\n",
        "clusterer = hdbscan.HDBSCAN(cluster_selection_epsilon=0.0022)\n",
        "df = data14\n",
        "clusterer.fit(df[['lon', 'lat']])\n",
        "df['cluster'] = clusterer.labels_\n",
        "print(len(df['cluster'].unique()))\n",
        "print(len(df[df['cluster'] == -1]))\n",
        "df = df[df['cluster'] != -1]"
      ],
      "metadata": {
        "id": "caXk_OPGgdcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "색상 = []\n",
        "for kind in df['cluster']:\n",
        "    np.random.seed(kind + 10000)\n",
        "    \n",
        "    색상_temp = np.random.randint(250, size=(3, )).tolist()\n",
        "    if kind == -1:\n",
        "        색상_temp.extend([0])\n",
        "    else:\n",
        "        색상_temp.extend([170])\n",
        "    \n",
        "    색상.append(색상_temp)\n",
        "    \n",
        "df['색상'] = 색상\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "TI-p4bBagdZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustermap(df, 'lon','lat').to_html()"
      ],
      "metadata": {
        "id": "xYSDbPLKgdXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop = df.groupby('cluster').count()['lon'][df.groupby('cluster').count()['lon'] <= 25].index\n",
        "clustermap(df[~df['cluster'].isin(drop)], 'lon','lat').to_html()"
      ],
      "metadata": {
        "id": "x6vgkV0jgdUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('제거 전: ', len(df['cluster'].unique()))\n",
        "print('제거 후: ', len(df[~df['cluster'].isin(drop)]['cluster'].unique()))"
      ],
      "metadata": {
        "id": "2_e663MegdSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_delete = df[~df['cluster'].isin(drop)]\n",
        "store_delete = gpd.GeoDataFrame(store_delete, geometry= gpd.points_from_xy(store_delete.lon, store_delete.lat))"
      ],
      "metadata": {
        "id": "fC8SI9cUgdPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#같은 군집에 속하는 좌표들의 합집합을 구하고, 그 합집합의 중점 구하기\n",
        "aca_cluster = {\"cluster\":[],\"lon\":[], \"lat\":[]}\n",
        "\n",
        "for i in list(store_delete.cluster.unique()):\n",
        "    aca_cluster[\"cluster\"].append(i)\n",
        "    aca_cluster[\"lon\"].append(store_delete[store_delete.cluster == i].unary_union.centroid.x)\n",
        "    aca_cluster[\"lat\"].append(store_delete[store_delete.cluster == i].unary_union.centroid.y)\n",
        "    \n",
        "store_cluster_df = pd.DataFrame(aca_cluster)\n",
        "store_cluster_geo = gpd.GeoDataFrame(store_cluster_df, geometry = gpd.points_from_xy(store_cluster_df.lon,store_cluster_df.lat))\n",
        "store_cluster_geo.crs = geo.crs"
      ],
      "metadata": {
        "id": "1rl9pOrVgdM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##학원가 클러스터링"
      ],
      "metadata": {
        "id": "0zkYrdp7g8VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HDBSCAN으로 학원가 클러스터링\n",
        "clusterer = hdbscan.HDBSCAN(cluster_selection_epsilon=0.003)\n",
        "df = academy \n",
        "clusterer.fit(df[['X', 'Y']])\n",
        "df['cluster'] = clusterer.labels_\n",
        "print(len(df['cluster'].unique()))\n",
        "print(len(df[df['cluster'] == -1]))\n",
        "df = df[df['cluster'] != -1]"
      ],
      "metadata": {
        "id": "CWp7WjwbgdKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "색상 = []\n",
        "for kind in df['cluster']:\n",
        "    np.random.seed(kind + 10000)\n",
        "    \n",
        "    색상_temp = np.random.randint(250, size=(3, )).tolist()\n",
        "    if kind == -1:\n",
        "        색상_temp.extend([0])\n",
        "    else:\n",
        "        색상_temp.extend([170])\n",
        "    \n",
        "    색상.append(색상_temp)\n",
        "    \n",
        "df['색상'] = 색상\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "NKOaGy5rgdHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustermap(df, 'X','Y').to_html()"
      ],
      "metadata": {
        "id": "_pOiSm1ogxDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop = df.groupby('cluster').count()['X'][df.groupby('cluster').count()['X'] <= 20].index\n",
        "clustermap(df[~df['cluster'].isin(drop)], 'X','Y').to_html()"
      ],
      "metadata": {
        "id": "IfjmPx2KgxBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('제거 전: ', len(df['cluster'].unique()))\n",
        "print('제거 후: ', len(df[~df['cluster'].isin(drop)]['cluster'].unique()))"
      ],
      "metadata": {
        "id": "e1aqlVz2gw-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "academy_delete = df[~df['cluster'].isin(drop)]\n",
        "academy_delete = gpd.GeoDataFrame(academy_delete, geometry= gpd.points_from_xy(academy_delete.X, academy_delete.Y))"
      ],
      "metadata": {
        "id": "Nxx1x_UKgw7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#같은 군집에 속하는 좌표들의 합집합을 구하고, 그 합집합의 중점 구하기\n",
        "aca_cluster = {\"cluster\":[],\"lon\":[], \"lat\":[]}\n",
        "\n",
        "for i in list(academy_delete.cluster.unique()):\n",
        "    aca_cluster[\"cluster\"].append(i)\n",
        "    aca_cluster[\"lon\"].append(academy_delete[academy_delete.cluster == i].unary_union.centroid.x)\n",
        "    aca_cluster[\"lat\"].append(academy_delete[academy_delete.cluster == i].unary_union.centroid.y)\n",
        "    \n",
        "academy_cluster_df = pd.DataFrame(aca_cluster)\n",
        "academy_cluster_geo = gpd.GeoDataFrame(academy_cluster_df, geometry = gpd.points_from_xy(academy_cluster_df.lon,academy_cluster_df.lat))\n",
        "academy_cluster_geo.crs = geo.crs"
      ],
      "metadata": {
        "id": "vvjTqHoYgw5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##지수 생성용 전처리"
      ],
      "metadata": {
        "id": "rjhguW9BhhVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그리드 별 개수 구해서 추가하는 함수 정의\n",
        "def grid_count(df, name):\n",
        "    df = df.groupby('id').count().reset_index()\n",
        "    df = df[['id','SIG_KOR_NM']]\n",
        "    df.columns = ['id', name]\n",
        "    return df\n",
        "\n",
        "# 그리드 별 평균 구해서 추가하는 함수 정의\n",
        "def grid_mean(df, name):\n",
        "    df = df.groupby('id').mean().reset_index()\n",
        "    df = df[['id','SIG_KOR_NM']]\n",
        "    df.columns = ['id', name]\n",
        "    return df"
      ],
      "metadata": {
        "id": "44YVzxAmgw2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###안전 지수"
      ],
      "metadata": {
        "id": "aZFk8NU2hrR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그리드 별 가로등 개수 구하기\n",
        "df_light = grid_count(street_lights, '가로등')\n",
        "\n",
        "# 그리드 별 파출소 개수 구하기\n",
        "df_police_office = grid_count(police_office, '파출소')\n",
        "\n",
        "# 그리드 별 cctv 개수 구하기\n",
        "df_cctv = cctv.groupby('id').sum().reset_index()[['id','카메라대수']]\n",
        "df_cctv['카메라대수'] = df_cctv['카메라대수']*9"
      ],
      "metadata": {
        "id": "OvutcKfjgw0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "dfs = [geo, df_light, df_police_office, df_cctv]\n",
        "df_merge = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), dfs)\n",
        "df_merge = df_merge.drop(['left','top','right','bottom','SIG_CD','SIG_KOR_NM'],axis=1)\n",
        "safety = df_merge"
      ],
      "metadata": {
        "id": "Bk5wiTokhc40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###교통 지수"
      ],
      "metadata": {
        "id": "FR_xBSsth0wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그리드 별 버스 별 배차 개수 구하기\n",
        "df_bus = bus[['id','BRT','광역버스','지선버스','간선버스','마을버스']]\n",
        "df_bus=df_bus.groupby([\"id\"])['BRT','광역버스','지선버스','간선버스','마을버스'].sum().reset_index()\n",
        "\n",
        "#  그리드 별 중앙 좌표와 가까운 역, 터미널과의 거리 구하기\n",
        "station = pd.read_csv('stations.csv')\n",
        "station_geo= gpd.GeoDataFrame(station, geometry = gpd.points_from_xy(station.경도, station.위도))\n",
        "station_geo.crs = geo.crs\n",
        "\n",
        "distance_station = []\n",
        "\n",
        "for i in geo['geometry']:\n",
        "    temp = []\n",
        "    for j in station_geo['geometry']:\n",
        "        temp.append(i.distance(j))\n",
        "    \n",
        "    distance_station.append(min(temp)) \n",
        "    \n",
        "station_dist = geo.copy()\n",
        "station_dist[\"역 터미널\"] = distance_station\n",
        "station_dist = station_dist[['id', '역 터미널']]"
      ],
      "metadata": {
        "id": "WqYiwnW9hczm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "dfs = [geo, df_bus, station_dist]\n",
        "df_merge = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), dfs)\n",
        "df_merge = df_merge.drop(['left','top','right','bottom','SIG_CD','SIG_KOR_NM'],axis=1)"
      ],
      "metadata": {
        "id": "pGiWh389hcxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 거리가 멀수록 페널티를 주기 위해 Hyperbolic Tangent 도함수에 넣어준 뒤, 정규화를 진행합니다\n",
        "def diff_tanh(x):\n",
        "    return 4/(np.exp(2*x)+2+np.exp(-2*x))\n",
        "\n",
        "dfdf = diff_tanh(df_merge['역 터미널'])\n",
        "\n",
        "dfdf = pd.DataFrame(dfdf, columns=['역 터미널'])\n",
        "df_merge['역 터미널']=dfdf['역 터미널']\n",
        "transport=df_merge"
      ],
      "metadata": {
        "id": "o0hEcIF9hcuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###생활 편의지수"
      ],
      "metadata": {
        "id": "gp0jgD3wh8eV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그리드 별 병원 개수 구하기\n",
        "df_hospital = grid_count(hospital, '병원')\n",
        "\n",
        "# 그리드 별 은행 개수 구하기\n",
        "df_banks = grid_count(banks, '은행')\n",
        "\n",
        "# 그리드 별 학교 개수 구하기\n",
        "df_schools = school.groupby(['id','학교구분']).count().unstack()\n",
        "df_schools = df_schools[df_schools.columns[0:3]].reset_index()\n",
        "df_schools.columns = ['id','고등학교', '중학교', '초등학교']\n",
        "\n",
        "# 그리드 별 공원 개수 구하기\n",
        "df_parks = grid_count(parks, '공원')\n",
        "\n",
        "# 그리드 별 학원 개수 구하기\n",
        "df_academy = grid_count(academy, '학원')\n",
        "\n",
        "# 그리드 별 편의점 개수 구하기\n",
        "df_stores = grid_count(stores, '편의점')\n",
        "\n",
        "# 그리드 별 마트 개수 구하기\n",
        "df_mart = grid_count(mart, '마트')\n",
        "\n",
        "# 그리드 별 약국 개수 구하기\n",
        "df_pharmacy = grid_count(pharmacy, '약국')\n",
        "\n",
        "# 그리드 별 중앙 좌표와 가까운 상권과의 거리 구하기\n",
        "distance_store = []\n",
        "for i in geo['geometry']:\n",
        "    temp = []\n",
        "    for j in store_cluster_geo['geometry']:\n",
        "        temp.append(i.distance(j))\n",
        "    \n",
        "    distance_store.append(min(temp))\n",
        "store_dist = geo.copy()\n",
        "store_dist[\"상권\"] = distance_store\n",
        "store_dist = store_dist[['id', '상권']]\n",
        "\n",
        "\n",
        "# 그리드 별 중앙 좌표와 가까운 학원가와의 거리 구하기\n",
        "distance_academy = []\n",
        "for i in geo['geometry']:\n",
        "    temp = []\n",
        "    for j in academy_cluster_geo['geometry']:\n",
        "        temp.append(i.distance(j))\n",
        "    \n",
        "    distance_academy.append(min(temp)) \n",
        "academy_dist = geo.copy()\n",
        "academy_dist[\"학원가\"] = distance_academy\n",
        "academy_dist = academy_dist[['id', '학원가']]"
      ],
      "metadata": {
        "id": "w9U4Pu4bh-5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "dfs = [geo, df_hospital, df_banks, df_schools, df_parks, df_academy, \n",
        "       df_stores, df_pharmacy, df_mart, store_dist, academy_dist]\n",
        "df_merge = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), dfs)\n",
        "df_merge = df_merge.drop(['left','top','right','bottom','SIG_CD','SIG_KOR_NM'],axis=1)"
      ],
      "metadata": {
        "id": "5ulkHHGniBTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 거리가 멀수록 페널티를 주기 위해 Hyperbolic Tangent 도함수에 넣어준 뒤, 정규화를 진행합니다\n",
        "def diff_tanh(x):\n",
        "    return 4/(np.exp(2*x)+2+np.exp(-2*x))\n",
        "\n",
        "dfdf = diff_tanh(df_merge[['상권','학원가']])\n",
        "df_merge[['상권','학원가']]=dfdf[['상권','학원가']]\n",
        "life = df_merge"
      ],
      "metadata": {
        "id": "yTdURH_6iBQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PCA"
      ],
      "metadata": {
        "id": "50YFzcu2iHzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###생활지수"
      ],
      "metadata": {
        "id": "ufPAw5FXiJNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "은행, 초등학교, 중학교, 고등학교, 공원, 학원, 편의점, 약국, 마트, 병원, 그리드별 가까운 상권/학원가와의 직선거리"
      ],
      "metadata": {
        "id": "qIT9qPrJiWvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NA 값은 0개이기에, 0으로 입력해준다.\n",
        "life['은행']=life['은행'].fillna(0)\n",
        "life['고등학교']=life['고등학교'].fillna(0)\n",
        "life['중학교']=life['중학교'].fillna(0)\n",
        "life['초등학교']=life['초등학교'].fillna(0) \n",
        "life['공원']=life['공원'].fillna(0)\n",
        "life['학원']=life['학원'].fillna(0)\n",
        "life['편의점']=life['편의점'].fillna(0) \n",
        "life['약국']=life['약국'].fillna(0)\n",
        "life['마트']=life['마트'].fillna(0)\n",
        "life['병원']=life['병원'].fillna(0)"
      ],
      "metadata": {
        "id": "Qdd2fbwkiBOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA 후, plot_grid_map을 하기 위해 ID가 필요하므로 미리 추출한다.\n",
        "id=life['id']\n",
        "\n",
        "# PCA를 위해 x 설정.\n",
        "x=life[['은행','고등학교','중학교','초등학교','공원','학원','편의점','약국','마트','상권','학원가']]\n",
        "\n",
        "# PCA를 활용하여 지수를 만드는 것이기에, n_components 1로 고정.\n",
        "\n",
        "pca= PCA(n_components = 1)\n",
        "PC=pca.fit_transform(x)\n",
        "result1 = pd.DataFrame(PC, columns=['PC1'])\n",
        "result1['id']=id # pca결과에 id 데이터 추가.\n",
        "\n",
        "# PCA PC1값에 minmax scaling을 해주었다. \n",
        "# 이유: 다중회귀분석 \n",
        "min_max_scaler = MinMaxScaler(feature_range=(5,100))\n",
        "x=result1['PC1']\n",
        "x=x.to_numpy(dtype=float)\n",
        "x=x.reshape(-1,1)\n",
        "x1= min_max_scaler.fit_transform(x)\n",
        "result1 = pd.DataFrame(x1, columns=['PC1'])\n",
        "result1['id']=id # pca결과에 id 데이터 추가.\n",
        "life_rate = result1"
      ],
      "metadata": {
        "id": "KRjvWR_XiBLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###안전지수"
      ],
      "metadata": {
        "id": "_hr7gzYMiOhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "가로등, 파출소, CCTV 대수"
      ],
      "metadata": {
        "id": "iVWRKD3-iQte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NA 값은 0개이기에, 0으로 채워준다.\n",
        "safety['가로등']=safety['가로등'].fillna(0)\n",
        "safety['파출소']=safety['파출소'].fillna(0)\n",
        "safety['카메라대수']=safety['카메라대수'].fillna(0)"
      ],
      "metadata": {
        "id": "cfFTh2OOiBIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA 후, plot_grid_map을 하기 위해 ID가 필요하므로 미리 추출한다.\n",
        "id=safety['id']\n",
        "x=safety[['가로등','파출소','카메라대수']]\n",
        "\n",
        "# PCA를 활용하여 지수를 만드는 것이기에, n_components 1로 고정.\n",
        "pca= PCA(n_components = 1)\n",
        "PC=pca.fit_transform(x)\n",
        "result2 = pd.DataFrame(PC, columns=['PC1'])\n",
        "result2['id']=id\n",
        "\n",
        "# PCA PC1값에 minmax scaling을 해주었다. \n",
        "# 이유: 다중회귀분석 \n",
        "x=result2['PC1']\n",
        "x=x.to_numpy(dtype=float)\n",
        "x=x.reshape(-1,1)\n",
        "x1= min_max_scaler.fit_transform(x)\n",
        "result2 = pd.DataFrame(x1, columns=['PC1'])\n",
        "result2['id']=id \n",
        "safety_rate = result2"
      ],
      "metadata": {
        "id": "hO1UF33QiBFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###교통지수"
      ],
      "metadata": {
        "id": "FYB8-6w2ieOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BRT, 광역, 지선, 간선, 마을버스 기준 그리드별 배차 횟수, 그리드별 중앙 좌표와 가까운 역, 터미널과의 거리"
      ],
      "metadata": {
        "id": "I7e0GQB6if2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transport['BRT']=transport['BRT'].fillna(0) # NA값 0으로 대체\n",
        "transport['광역버스']=transport['광역버스'].fillna(0)\n",
        "transport['지선버스']=transport['지선버스'].fillna(0)\n",
        "transport['간선버스']=transport['간선버스'].fillna(0)\n",
        "transport['마을버스']=transport['마을버스'].fillna(0)"
      ],
      "metadata": {
        "id": "-mFAETBpiaak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA 후, plot_grid_map을 하기 위해 ID가 필요하므로 미리 추출한다.\n",
        "id=transport['id']\n",
        "x=transport[['BRT','광역버스','지선버스','간선버스','마을버스','역 터미널']]\n",
        "\n",
        "# PCA를 활용하여 지수를 만드는 것이기에, n_components 1로 고정.\n",
        "pca= PCA(n_components = 1)\n",
        "PC=pca.fit_transform(x)\n",
        "result3 = pd.DataFrame(PC, columns=['PC1'])\n",
        "result3['id']=id\n",
        "\n",
        "# PCA PC1값에 minmax scaling을 해주었다. \n",
        "# 이유: 다중회귀분석 \n",
        "min_max_scaler = MinMaxScaler(feature_range=(5,100))\n",
        "x=result3['PC1']\n",
        "x=x.to_numpy(dtype=float)\n",
        "x=x.reshape(-1,1)\n",
        "x1= min_max_scaler.fit_transform(x)\n",
        "result3 = pd.DataFrame(x1, columns=['PC1'])\n",
        "result3['id']=id \n",
        "transport_rate = result3"
      ],
      "metadata": {
        "id": "g-FHAU7IiaYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###생활 편의 지수"
      ],
      "metadata": {
        "id": "gAGTRap0ik5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA 결과를 바탕으로 geo(격자) 데이터와 합쳐준다.\n",
        "pca = pd.merge(life_rate,geo,on='id',how='outer')\n",
        "pca = gpd.GeoDataFrame(pca)\n",
        "\n",
        "plot_grid_map(pca, col = 'PC1', title = '생활 편의 지수', k=12,\n",
        "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Purples', percen = False)"
      ],
      "metadata": {
        "id": "8L7n2rKxiaVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###안전 지수"
      ],
      "metadata": {
        "id": "IKU8_cdWirbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA 결과를 바탕으로 geo(격자) 데이터와 합쳐준다.\n",
        "pca = pd.merge(safety_rate,geo,on='id',how='outer')\n",
        "pca = gpd.GeoDataFrame(pca)\n",
        "\n",
        "plot_grid_map(pca, col = 'PC1', title = '안전 지수', k=12,\n",
        "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Greens', percen = False)"
      ],
      "metadata": {
        "id": "EwRSl2lgiaTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###교통 지수"
      ],
      "metadata": {
        "id": "W0akiAaFit1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA 결과를 바탕으로 geo(격자) 데이터와 합쳐준다.\n",
        "pca = pd.merge(transport_rate,geo,on='id',how='outer')\n",
        "pca = gpd.GeoDataFrame(pca)\n",
        "\n",
        "plot_grid_map(pca, col = 'PC1', title = '교통 지수', k=12,\n",
        "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Blues', percen = False)"
      ],
      "metadata": {
        "id": "CRJ2jPvDiaQm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}