{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Visualization"
      ],
      "metadata": {
        "id": "MSi0PQz9DcpS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TMqC9m3DP0y"
      },
      "outputs": [],
      "source": [
        "import mapclassify as mc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import rgb2hex\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib\n",
        "%config InlineBackend.figure_format='retina' #화질 좋게 해주기\n",
        "\n",
        "import matplotlib.font_manager as fm\n",
        "nanumr = fm.FontProperties(fname='NanumSquareOTFRegular.otf', size=18)\n",
        "nanumb = fm.FontProperties(fname='NanumSquareOTFBold.otf', size=18)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_grid_map(df, col, k = 6, title = 'No name', mode = None, cls_dict = None, how = None,\n",
        "                  annotation = False, percen = True, colors = 'Blues', c_mode = 'NaturalBreaks'):\n",
        "    \n",
        "    # 주어진 데이터를 적절히 단계별로 나누는 코드\n",
        "    if mode == 'cont_classify':\n",
        "        dfdf = df[df[col]>0]\n",
        "        if c_mode == 'NaturalBreaks':\n",
        "            quantiles = mc.NaturalBreaks(dfdf[col].dropna(), k = k)\n",
        "        elif c_mode == 'FisherJenks':\n",
        "            quantiles = mc.FisherJenks(dfdf[col].dropna(), k = k)\n",
        "        df['cls_value'] = quantiles.find_bin(df[col]).astype('str')\n",
        "        df.loc[df[col].isnull(), 'cls_value'] = 'No Data'\n",
        "        df.loc[df[col]<0, 'cls_value'] = 'Minus'\n",
        "        cmap = plt.cm.get_cmap(colors, k)\n",
        "        cmap_list = [rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
        "        if len(np.where(df['cls_value'].unique() == 'Minus')[0]) != 0:\n",
        "            cmap_list.append('#F78181')\n",
        "        if len(np.where(df['cls_value'].unique() == 'No Data')[0]) != 0:\n",
        "            cmap_list.append('#bdbdbd')\n",
        "        cmap_with_grey = ListedColormap(cmap_list)\n",
        "    if mode == 'cluster':\n",
        "        k = len(df[col].unique())\n",
        "        df[col].fillna(-2, inplace=True)\n",
        "        df[col].astype('int')\n",
        "        df['cls_value'] = df[col] + 1\n",
        "        df.sort_values('cls_value')\n",
        "        df.loc[df[col]<0, 'cls_value'] = 'No Data'\n",
        "        cmap = plt.cm.get_cmap(colors, k)\n",
        "        cmap_list = [rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
        "        if len(np.where(df['cls_value'].unique() == 'No Data')[0]) != 0:\n",
        "            cmap_list.append('#bdbdbd')\n",
        "        cmap_with_grey = ListedColormap(cmap_list)\n",
        "    \n",
        "        \n",
        "    # plot 그리는 코드\n",
        "    fig, ax = plt.subplots(figsize=(12, 10))\n",
        "    df.plot(column='cls_value', edgecolor='k', cmap=cmap_with_grey,linewidth=0.05,\n",
        "             legend=True, legend_kwds=dict(loc='upper right'),ax=ax)\n",
        "    \n",
        "    # 범례이름 바꾸는 코드\n",
        "    if mode == 'cont_classify':\n",
        "        legend_labels = ax.get_legend().get_texts()\n",
        "        upper_bounds = quantiles.bins\n",
        "        bounds = []\n",
        "        for index, upper_bound in enumerate(upper_bounds):\n",
        "            if index == 0:\n",
        "                lower_bound = float(df.cls_value.min())\n",
        "            else:\n",
        "                lower_bound = float(upper_bounds[index-1])\n",
        "            \n",
        "            if percen:\n",
        "                bound = '{}% - {}%'.format(round(lower_bound, 1), round(upper_bound, 1))\n",
        "            else:\n",
        "                bound = '{} - {}'.format(round(lower_bound, 2), round(upper_bound, 2))\n",
        "            bounds.append(bound)\n",
        "    if mode == 'cluster':\n",
        "        if 'No Data' in list(df['cls_value'].unique()):\n",
        "            legend_labels = ax.get_legend().get_texts()\n",
        "            bounds = []\n",
        "            for num in list(price_merge['cls_value'].unique())[0:-1]:\n",
        "                bound = 'cluster {}'.format(round(num))\n",
        "                bounds.append(bound)     \n",
        "        else:\n",
        "            legend_labels = ax.get_legend().get_texts()\n",
        "            bounds = []\n",
        "            for num in list(price_merge['cls_value'].unique()):\n",
        "                bound = 'cluster {}'.format(num)\n",
        "                bounds.append(bound)  \n",
        "        \n",
        "    # replace the numerical legend labels\n",
        "    for bound, legend_label in zip(bounds, legend_labels):\n",
        "        legend_label.set_text(bound)\n",
        "        \n",
        "    ax.axis('off')\n",
        "    ax.set_title(title, fontdict={'fontsize': '25', 'fontweight' : '3'} , fontproperties=nanumr)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "rca6R4q7DllV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1) 시기별 이슈 확인"
      ],
      "metadata": {
        "id": "lgsHG3YsJGEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###시계열 거래 데이터 시각화"
      ],
      "metadata": {
        "id": "Jyrd_TItDzIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# datetime 형태로 바꿔줍니다\n",
        "\n",
        "df3, df4, df5, df6  = data3, data4, data5, data6\n",
        "df7, df8, df9, df10  = data7, data8, data9, data10\n",
        "\n",
        "df3['계약년월'] = pd.to_datetime(df3['계약년월'], format='%Y%m')\n",
        "df4['계약년월'] = pd.to_datetime(df4['계약년월'], format='%Y%m')\n",
        "df5['계약년월'] = pd.to_datetime(df5['계약년월'], format='%Y%m')\n",
        "df6['계약년월'] = pd.to_datetime(df6['계약년월'], format='%Y%m')\n",
        "df7['계약년월'] = pd.to_datetime(df7['계약년월'], format='%Y%m')\n",
        "df8['계약년월'] = pd.to_datetime(df8['계약년월'], format='%Y%m')\n",
        "df9['계약년월'] = pd.to_datetime(df9['계약년월'], format='%Y%m')\n",
        "df10['계약년월'] = pd.to_datetime(df10['계약년월'], format='%Y%m')"
      ],
      "metadata": {
        "id": "BONhRmwaDyNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전월세 데이터를 전세와 월세로 구분합니다\n",
        "# 1이 전세, 2가 월세\n",
        "\n",
        "df71 = df7[df7['전월세구분'] == '전세']\n",
        "df72 = df7[df7['전월세구분'] == '월세']\n",
        "df81 = df8[df8['전월세구분'] == '전세']\n",
        "df82 = df8[df8['전월세구분'] == '월세']\n",
        "df91 = df9[df9['전월세구분'] == '전세']\n",
        "df92 = df9[df9['전월세구분'] == '월세']\n",
        "df101 = df7[df7['전월세구분'] == '전세']\n",
        "df102 = df7[df7['전월세구분'] == '월세']"
      ],
      "metadata": {
        "id": "N-tY4P3aD7-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 월별로 계약 건수를 세주는 함수를 만듭니다\n",
        "\n",
        "def counting(df):\n",
        "    df = df.set_index('계약년월')\n",
        "    df = df.groupby([pd.Grouper(freq='1M')]).count()\n",
        "    return df"
      ],
      "metadata": {
        "id": "J3IeSOyHD8oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 데이터프레임으로 합쳐줍니다\n",
        "\n",
        "df = DataFrame()\n",
        "df['apt_m'] = counting(df3)['계약일']\n",
        "df['vil_m'] = counting(df4)['계약일']\n",
        "df['house_m'] = counting(df5)['계약일']\n",
        "df['op_m'] = counting(df6)['계약일']\n",
        "df['apt_j'] = counting(df71)['계약일']\n",
        "df['vil_j'] = counting(df81)['계약일']\n",
        "df['house_j'] = counting(df91)['계약일']\n",
        "df['op_j'] = counting(df101)['계약일']\n",
        "df['apt_w'] = counting(df72)['계약일']\n",
        "df['vil_w'] = counting(df82)['계약일']\n",
        "df['house_w'] = counting(df92)['계약일']\n",
        "df['op_w'] = counting(df102)['계약일']\n",
        "\n",
        "df = df.reset_index()"
      ],
      "metadata": {
        "id": "D8-BqwyID_26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['apt'] = df['apt_m'] + df['apt_j'] + df['apt_w']\n",
        "df['vil'] = df['vil_m'] + df['vil_j'] + df['vil_w']\n",
        "df['house'] = df['house_m'] + df['house_j'] + df['house_w']\n",
        "df['op'] = df['op_m'] + df['op_j'] + df['op_w']\n",
        "df['buy'] = df['apt_m'] + df['vil_m'] + df['house_m'] + df['op_m']\n",
        "df['jun'] = df['apt_j'] + df['vil_j'] + df['house_j'] + df['op_j']\n",
        "df['wol'] = df['apt_w'] + df['vil_w'] + df['house_w'] + df['op_w']\n",
        "df['all'] = df['apt'] + df['vil'] + df['house'] + df['op']\n",
        "deal = df"
      ],
      "metadata": {
        "id": "FyV25RhpEFIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###실거래량 추이"
      ],
      "metadata": {
        "id": "4krkAMBxEJnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
        "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['all'], line = dict(color='#0B0B61', width=3)))\n",
        "fig.update_layout(title='실거래량 추이', plot_bgcolor='#F8F7F1')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_5DWVVlmEMXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###거주형태별 실거래량 추이"
      ],
      "metadata": {
        "id": "E7hjF9RzEOUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
        "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['apt'], line = dict(color='#0B0B61', width=3), name='아파트'))\n",
        "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['vil'], line = dict(color='#404040', width=3), name='연립다세대'))\n",
        "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['house'], line = dict(color='#F3C706', width=3), name='단독다가구'))\n",
        "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['op'], line = dict(color='#0B6121', width=3), name='오피스텔'))\n",
        "fig.update_layout(title='거주형태별 거래량 추이', plot_bgcolor='#F8F7F1')\n",
        "fig.update_layout(legend=dict(\n",
        "    yanchor=\"top\",\n",
        "    y=0.99,\n",
        "    xanchor=\"left\",\n",
        "    x=0.01\n",
        "))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Y7WXf4gtEQhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###거래형태별 실거래량 추이"
      ],
      "metadata": {
        "id": "fV2xsFzuESgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
        "fig.add_trace(go.Scatter(x=df['계약년월'],y=df['buy'], line = dict(color='#0B0B61', width=3), name='매매'))\n",
        "fig.add_trace(go.Scatter(x=df['계약년월'],y=df['jun'], line = dict(color='#0B6121', width=3), name='전세'))\n",
        "fig.add_trace(go.Scatter(x=df['계약년월'],y=df['wol'], line = dict(color='#F3C706', width=3), name='월세'))\n",
        "fig.update_layout(title='거래형태별 거래량 추이', plot_bgcolor='#F8F7F1')\n",
        "fig.update_layout(legend=dict(\n",
        "    yanchor=\"top\",\n",
        "    y=0.99,\n",
        "    xanchor=\"left\",\n",
        "    x=0.01\n",
        "))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ZFEQHpAVHNV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2017 = pd.read_csv('2017.csv', encoding= 'utf-8')\n",
        "df2018 = pd.read_csv('2018.csv', encoding= 'utf-8')\n",
        "df2019 = pd.read_csv('2019.csv', encoding= 'utf-8')\n",
        "df2020 = pd.read_csv('2020.csv', encoding= 'utf-8')\n",
        "df2021 = pd.read_csv('2021.csv', encoding= 'utf-8')"
      ],
      "metadata": {
        "id": "YdvPCZskHVHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data concat\n",
        "df = pd.concat([df2017,df2018,df2019,df2020,df2021])"
      ],
      "metadata": {
        "id": "b693CgUeHcBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 길이 확인\n",
        "print('2017년: ',len(df2017))\n",
        "print('2018년: ',len(df2018))\n",
        "print('2019년: ',len(df2019))\n",
        "print('2020년: ',len(df2020))\n",
        "print('2021년: ',len(df2021))"
      ],
      "metadata": {
        "id": "vrkol1UPHeZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tokenizer&전처리"
      ],
      "metadata": {
        "id": "BbfFK6gUHPrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "qT2PQLUjHptf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 설정\n",
        "stopwords = ['않다','에서','있다','없다','그렇다','아니다','것','이다','의','가','이','은','들',\n",
        "             '는','좀','잘','걍','과','도','을','를','으로','자','에','와','한','하다','휴','수','부동산']"
      ],
      "metadata": {
        "id": "Ni_SFrNKHsV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 한글과 공백을 제외하고 모두 제거\n",
        "df['title'] = df['title'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "df['title'].replace('', np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "JKprpe4JHsTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###뉴스 개수 변화 추이"
      ],
      "metadata": {
        "id": "lBLIgR5-H_Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['years'] = pd.to_datetime(df['years'], format='%Y.%m.%d.')"
      ],
      "metadata": {
        "id": "d6CnOLJjHsQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def counting(df):\n",
        "    df = df.set_index('years')\n",
        "    df = df.groupby([pd.Grouper(freq='1M')]).count()\n",
        "    return df"
      ],
      "metadata": {
        "id": "tQQa2EpwIDIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = counting(df)"
      ],
      "metadata": {
        "id": "hcqqlmYRIDF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.drop(['contents','link','Unnamed: 5','Unnamed: 6','Unnamed: 7'],axis = 1)"
      ],
      "metadata": {
        "id": "j3IRkCJgIDDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "import plotly.io as pio\n",
        "\n",
        "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
        "fig.add_trace(go.Scatter(x=df2.index,y=df2['title'], line = dict(color='#0B0B61', width=3)))\n",
        "fig.update_layout(title='연월별 뉴스 보도 개수 추이', plot_bgcolor='#F8F7F1')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "1ENw7EZGIDA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###기사 제목 토큰화"
      ],
      "metadata": {
        "id": "OOBB78GMIHog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "token = []\n",
        "for sentence in df['title']:\n",
        "    temp_X = []\n",
        "    temp_X = okt.nouns(sentence) # 명사 토큰화\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "    token.append(temp_X)\n",
        "df['token'] = token\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(token)"
      ],
      "metadata": {
        "id": "txmvCDUTIC-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###기준에 따른 분류: 12개 구간 설정"
      ],
      "metadata": {
        "id": "JokBVoSiIMdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values('years')\n",
        "\n",
        "import datetime\n",
        "df_1 = df[df['years'] <'2017-04-01'] # 3 / 1,2,3\n",
        "df_2 = df[(df['years']>= '2017-04-01')&(df['years'] <'2017-07-01')] # 3 / 4,5,6\n",
        "df_3 = df[(df['years']>= '2017-07-01')&(df['years'] <'2017-11-01')] # 4 / 7,8,9,10\n",
        "df_4 = df[(df['years']>= '2017-11-01')&(df['years'] <'2018-01-01')] # 2 / 11,12\n",
        "df_5 = df[(df['years']>= '2018-01-01')&(df['years'] <'2018-05-01')] # 4 / 1,2,3,4\n",
        "df_6 = df[(df['years']>= '2018-05-01')&(df['years'] <'2019-02-01')] # 9\n",
        "df_7 = df[(df['years']>= '2019-02-01')&(df['years'] <'2019-10-01')] # 8\n",
        "df_8 = df[(df['years']>= '2019-10-01')&(df['years'] <'2020-01-01')] # 3\n",
        "df_9 = df[(df['years']>= '2020-01-01')&(df['years'] <'2020-05-01')] # 4\n",
        "df_10 = df[(df['years']>= '2020-05-01')&(df['years'] <'2020-08-01')] # 3\n",
        "df_11 = df[(df['years']>= '2020-08-01')&(df['years'] <'2020-11-01')] # 3\n",
        "df_12 = df[df['years']>= '2020-11-01'] # 2"
      ],
      "metadata": {
        "id": "kctSIvSNIC7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter # 단어 빈도 수 세기\n",
        "def tokenizing(df):\n",
        "    #konlpy로 명사만 추출하는 토큰화를 진행\n",
        "    words = np.hstack(df['token'].values)\n",
        "    word_count = Counter(words)\n",
        "    #print(word_count.most_common(20))\n",
        "    input = dict(word_count.most_common(300))\n",
        "    return input"
      ],
      "metadata": {
        "id": "LLBuQ3QvIC5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = tokenizing(df_1)\n",
        "df2 = tokenizing(df_2)\n",
        "df3 = tokenizing(df_3)\n",
        "df4 = tokenizing(df_4)\n",
        "df5 = tokenizing(df_5)\n",
        "df6 = tokenizing(df_6)\n",
        "df7 = tokenizing(df_7)\n",
        "df8 = tokenizing(df_8)\n",
        "df9 = tokenizing(df_9)\n",
        "df10 = tokenizing(df_10)\n",
        "df11 = tokenizing(df_11)\n",
        "df12= tokenizing(df_12)"
      ],
      "metadata": {
        "id": "CET7-NvLHsNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "워드 클라우드 그리기"
      ],
      "metadata": {
        "id": "xt-W810HIbOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format='retina'"
      ],
      "metadata": {
        "id": "T7BO3-1THsKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 워드클라우드를 그리는 함수 만들기\n",
        "from wordcloud import WordCloud, ImageColorGenerator\n",
        "from PIL import Image\n",
        "\n",
        "def wcdraw(inputs,width,height,path):\n",
        "    pic = np.array(Image.open(path))\n",
        "    image_colors = ImageColorGenerator(pic)\n",
        "    # 네모 모양으로 wordcloud 생성하기\n",
        "    wordcloud = WordCloud(font_path = 'NanumSquareOTFBold.otf', max_words=40,\n",
        "                          width=width,height=height,background_color ='white',)\n",
        "\n",
        "    # 워드 클라우드 그리기\n",
        "    wordcloud = wordcloud.generate_from_frequencies(inputs)\n",
        "    plt.figure(figsize = (15 , 10))\n",
        "    plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation='bilinear')\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "8LovkaDfHsIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 지도 모양으로 자르기\n",
        "pic = np.array(Image.open('pangyo.png'))\n",
        "wordcloud = WordCloud(font_path = 'NanumSquareOTFBold.otf', max_words=300, stopwords = '주택',\n",
        "                        width=2000,height=2500,background_color ='white',colormap = 'ocean',mask = pic)\n",
        "\n",
        "# 워드 클라우드 그리기\n",
        "wordcloud = wordcloud.generate_from_frequencies(tokenizing(df))\n",
        "plt.figure(figsize = (15 , 10))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TfZ4aM-8HsEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2017년 1월 1일 ~ 3월 31일\n",
        "wcdraw(df1,900,500,'1-1.png')\n",
        "\n",
        "# 2017년 4월 1일 ~ 7월 31일\n",
        "wcdraw(df2,900,500,'1-2.png')\n",
        "\n",
        "# 2017년 7월 1일 ~ 10월 31일\n",
        "wcdraw(df3, 1200,500, '1-3.png')\n",
        "\n",
        "#2017년 11월 ~ 2017년 12월 31일\n",
        "wcdraw(df4,600,500,'1-4.png')\n",
        "\n",
        "#2018년 1월 ~ 4월 30일\n",
        "wcdraw(df5, 600, 500, '2-1.png')\n",
        "\n",
        "# 2018년 5월 ~ 2019년 1월 \n",
        "wcdraw(df6, 1350,500,'2-2.png')\n",
        "\n",
        "#2019년 2월 ~ 2019년 9월\n",
        "wcdraw(df7, 1200, 500, '2-3.png')\n",
        "\n",
        "#2019년 10월 ~ 12월 31일\n",
        "wcdraw(df8, 450, 500, '2-4.png')\n",
        "\n",
        "# 2020년 1월 ~ 4월\n",
        "wcdraw(df9, 1200, 500, '3-1.png')\n",
        "\n",
        "# 2020년 5월 ~ 7월 31일\n",
        "wcdraw(df10, 900, 500, '3-2.png')\n",
        "\n",
        "# 2020년 8월 ~ 10월 31일\n",
        "wcdraw(df11, 900, 500, '3-3.png')\n",
        "\n",
        "# 2020년 11월 1일 ~ 12월 31일\n",
        "wcdraw(df12, 600, 500, '3-4.png')"
      ],
      "metadata": {
        "id": "9wywRtsVHsCD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}