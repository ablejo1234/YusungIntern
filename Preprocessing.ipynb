{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "VyIRiTqzUJeV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kge5df6kr7ft"
      },
      "outputs": [],
      "source": [
        "from geoband.API import *\n",
        "import folium\n",
        "import json\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "pd.options.display.float_format = '{:.5f}'.format\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pydeck as pdk\n",
        "import plotly.express as px\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = \"notebook_connected\"\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "col = px.colors.qualitative.Pastel\n",
        "\n",
        "from geopandas import GeoDataFrame\n",
        "from pandas import DataFrame\n",
        "import deckgljupyter.Layer as deckgl\n",
        "\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import random\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "np.random.seed(seed=42)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "random.seed(42)\n",
        "import hdbscan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GetCompasData('SBJ_2102_001', '2', '표제부.csv')\n",
        "GetCompasData('SBJ_2102_001', '3', '아파트(매매)_실거래가.csv')\n",
        "GetCompasData('SBJ_2102_001', '4', '연립다세대(매매)_실거래가.csv')\n",
        "GetCompasData('SBJ_2102_001', '5', '단독다가구(매매)_실거래가.csv')\n",
        "GetCompasData('SBJ_2102_001', '6', '오피스텔(매매)_실거래가.csv')\n",
        "GetCompasData('SBJ_2102_001', '7', '아파트(전월세)_실거래가.csv')\n",
        "GetCompasData('SBJ_2102_001', '8', '연립다세대(전월세)_실거래가.csv')\n",
        "GetCompasData('SBJ_2102_001', '9', '단독다가구(전월세)_실거래가.csv')\n",
        "GetCompasData('SBJ_2102_001', '10', '오피스텔(전월세)_실거래가.csv')\n",
        "GetCompasData('SBJ_2102_001', '14', '상권정보.csv')\n",
        "GetCompasData('SBJ_2102_001', '18', '개별공시지가(2017~2021).csv')\n",
        "GetCompasData('SBJ_2102_001', '19', '연령별_거주인구정보_격자.geojson')\n",
        "GetCompasData('SBJ_2102_001', '20', '전입자수.csv')\n",
        "GetCompasData('SBJ_2102_001', '21', '전출자수.csv')\n",
        "GetCompasData('SBJ_2102_001', '22', '연령별_인구현황.csv')\n",
        "GetCompasData('SBJ_2102_001', '28', '지역별_세대원수별_세대수.csv')\n",
        "GetCompasData('SBJ_2102_001', '29', '거주의사(향후).csv')\n",
        "GetCompasData('SBJ_2102_001', '31', '법정경계(읍면동).geojson')\n",
        "GetCompasData('SBJ_2102_001', '32', '행정경계(읍면동).geojson')"
      ],
      "metadata": {
        "id": "Q7-JNYK1UQ5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.read_csv('표제부.csv',encoding='utf-8')\n",
        "data3 = pd.read_csv('아파트(매매)_실거래가.csv', encoding='utf-8')\n",
        "data4 = pd.read_csv('연립다세대(매매)_실거래가.csv',  encoding='utf-8')\n",
        "data5 = pd.read_csv('단독다가구(매매)_실거래가.csv', encoding='utf-8')\n",
        "data6 = pd.read_csv('오피스텔(매매)_실거래가.csv',  encoding='utf-8')\n",
        "data7 = pd.read_csv('아파트(전월세)_실거래가.csv',  encoding='utf-8')\n",
        "data8 = pd.read_csv('연립다세대(전월세)_실거래가.csv', encoding='utf-8')\n",
        "data9 = pd.read_csv('단독다가구(전월세)_실거래가.csv', encoding='utf-8')\n",
        "data10 = pd.read_csv('오피스텔(전월세)_실거래가.csv', encoding='utf-8')\n",
        "data14 = pd.read_csv('상권정보.csv', encoding= 'utf-8')\n",
        "data18 = pd.read_csv('개별공시지가(2017~2021).csv', encoding='utf-8')\n",
        "data19 = gpd.read_file('연령별_거주인구정보_격자.geojson')\n",
        "data20 = pd.read_csv('전입자수.csv', encoding='utf-8')\n",
        "data21 = pd.read_csv('전출자수.csv', encoding='utf-8')\n",
        "data22 = pd.read_csv('연령별_인구현황.csv', encoding='utf-8')\n",
        "data28 = pd.read_csv('지역별_세대원수별_세대수.csv', encoding='utf-8')\n",
        "data29 = pd.read_csv('거주의사(향후).csv', encoding='utf-8')\n",
        "data31 = gpd.read_file('법정경계(읍면동).geojson')\n",
        "data32 = gpd.read_file('행정경계(읍면동).geojson')\n",
        "geo = gpd.read_file('final_geo.geojson')"
      ],
      "metadata": {
        "id": "sAPuyGVyowJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Data Preprocessing"
      ],
      "metadata": {
        "id": "1BO2DPKyp0Ft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1) 매매, 전월세, 공시지가 데이터 전처리"
      ],
      "metadata": {
        "id": "7OMAtDahp25W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "지번주소가 다른 방식(ex. 본번, 부번)으로 제공되어있는 매매, 전월세, 공시지가 데이터를 동일한 지번주소로 통합"
      ],
      "metadata": {
        "id": "NBFcM-tUp6ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시군구, 본번, 부번 합쳐서 지번주소 만드는 함수 정의\n",
        "\n",
        "def get_address(data):\n",
        "    data = data.reset_index()\n",
        "    df = data\n",
        "    df['부번']=df['부번'].astype(str)\n",
        "    df['본번']=df['본번'].astype(str)\n",
        "    df['시군구']=df['시군구'].astype(str)\n",
        "    \n",
        "    drop = df.loc[(df['본번'] == '0') & (df['부번'] == '0')].index\n",
        "    df = df.drop(drop)\n",
        "    \n",
        "    # 유형 별로 주소 데이터 나누기\n",
        "    df1 = df[df['본번'] == '0'][['index','시군구','본번','부번']]\n",
        "    df2 = df[df['부번'] == '0'][['index','시군구','본번','부번']]\n",
        "    df3 = df.loc[(df['본번'] != '0') & (df['부번'] != '0')][['index','시군구','본번','부번']]\n",
        "    \n",
        "    # 각 유형에 따라 번지 부여\n",
        "    df1['입력주소'] = \" \" + df1['시군구'] + \" \" + df1['부번'] + \"번지\"\n",
        "    df2['입력주소'] = \" \" + df2['시군구'] + \" \" + df2['본번'] + \"번지\"\n",
        "    df3['입력주소'] = \" \" + df3['시군구']+ \" \" + df3['본번'] + \"-\" + df3['부번'] + \"번지\"\n",
        "    \n",
        "    # 3개의 데이터 Merging\n",
        "    from functools import reduce\n",
        "    dfs = [df1,df2,df3]\n",
        "    df_merge = reduce(lambda left, right: \n",
        "                      pd.merge(left, right, on=['index','입력주소'], how='outer'), dfs)\n",
        "    df_merge = df_merge[['index','입력주소']]\n",
        "    df_final = pd.merge(data,df_merge,on = 'index',how='outer')\n",
        "    return df_final"
      ],
      "metadata": {
        "id": "NLD_-QG0owEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###매매, 전월세 데이터 지번주소 뽑아내기"
      ],
      "metadata": {
        "id": "FrWxPtkUqQM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터에서 지번 주소들 뽑아내기\n",
        "\n",
        "df1 = get_address(data3)[['index','입력주소']]\n",
        "df2 = get_address(data4)[['index','입력주소']]\n",
        "df3 = get_address(data6)[['index','입력주소']]\n",
        "df4 = get_address(data7)[['index','입력주소']]\n",
        "df5 = get_address(data8)[['index','입력주소']]\n",
        "df6 = get_address(data10)[['index','입력주소']]\n",
        "\n",
        "# Data Merging\n",
        "from functools import reduce\n",
        "dfs = [df1,df2,df3,df4,df5,df6]\n",
        "df_merge = reduce(lambda left, right: pd.merge(left, right, on=['index','입력주소'], how='outer'), dfs)\n",
        "\n",
        "df_merge['happy'] = 1\n",
        "df_merge = df_merge[['입력주소','happy']]\n",
        "address = df_merge.drop_duplicates().reset_index()\n",
        "\n",
        "address.to_csv('address.csv', encoding='utf-8') # Geocoding 할 수 있도록 데이터 저장"
      ],
      "metadata": {
        "id": "w6Wh_-Bfov33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###공시지가 데이터에서 주택만 추출"
      ],
      "metadata": {
        "id": "53Ap4aTEqafG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "표제부 데이터에서 아파트, 단독주택 데이터만 추출하여 새 변수로 저장"
      ],
      "metadata": {
        "id": "p0uoKlkkqgtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 공시지가 데이터에서 입력주소, 주소 코드 만들어주기\n",
        "\n",
        "data18['지번'] = data18['지번'].str.replace(\"_\",\"-\")  # 지번 바꾸기\n",
        "data18['입력주소'] = data18['법정동명'] + \" \" + data18['지번'] + \"번지\"\n",
        "data18['법정동코드'] = data18['법정동코드'].astype(str)\n",
        "data18['code'] = data18['법정동코드'] + '/' + data18['지번']"
      ],
      "metadata": {
        "id": "_lgHeqHKovw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#표제부에서 주택(아파트, 단독) 에 해당하는 지번만 추출하기\n",
        "\n",
        "data2['주용도코드명'] = data2['주용도코드명'].fillna('결측치')\n",
        "house = data2[data2['주용도코드명'].str.contains('주택')] #표제부에서 주택만 추출\n",
        "house['지'] = house['지'].astype(str)\n",
        "house['번'] = house['번'].astype(str)\n",
        "house['법정동코드'] = house['법정동코드'].astype(str)\n",
        "house['시군구코드'] = house['시군구코드'].astype(str)\n",
        "\n",
        "# 지번 변수 만들기\n",
        "drop = house.loc[(house['지'] == '0') & (house['번'] == '0')].index\n",
        "house = house.drop(drop)\n",
        "house1 = house[house['지'] == '0']\n",
        "house2 = house[house['번'] == '0']\n",
        "house3 = house.loc[(house['지'] != '0') & (house['번'] != '0')]\n",
        "house1['지번'] = house1['번']\n",
        "house3['지번'] = house3['번'] + '-' + house3['지']\n",
        "\n",
        "# Data Merging\n",
        "house = pd.concat([house1,house3])\n",
        "house = house[['대지위치','건물명','주용도코드명','시군구코드','법정동코드','지번','사용승인일']]\n",
        "house['code'] = house['시군구코드']+ house['법정동코드'] + '/' + house['지번'] #코드 만들기\n",
        "house = house[['대지위치','주용도코드명','건물명','code','사용승인일']]"
      ],
      "metadata": {
        "id": "KyGvmfi9ovtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 표제부 데이터와 공시지가 데이터 합쳐주기 \n",
        "\n",
        "houseonly = pd.merge(data18, house, on = 'code') #주택만 추출된 데이터!\n",
        "houseonly = houseonly[['건물명','법정동명','기준년도','공시지가','대지위치','주용도코드명','사용승인일']]\n",
        "houseonly.to_csv('houseonly.csv', encoding='utf-8') #Geocoding 위해서 저장"
      ],
      "metadata": {
        "id": "sukpY5hzovrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2) Geocoding 된 데이터를 격자에 부여"
      ],
      "metadata": {
        "id": "LhHnGW3PrhlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geocoding Tool을 활용하여, 지번주소를 위경도 좌표 데이터로 변환하는 plus_grid 함수 정의"
      ],
      "metadata": {
        "id": "xuJwrxNUsgJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 위경도 데이터를 격자로 부여하는 함수 정의\n",
        "\n",
        "def plus_grid(df, geo, X, Y, drop=True):\n",
        "    data1= gpd.GeoDataFrame(df, geometry = gpd.points_from_xy(df[X], df[Y])) #X는 경도, Y는 위도\n",
        "    merge_data = gpd.sjoin(data1, geo, op = \"within\", how = \"right\")\n",
        "    merge_data.crs = geo.crs\n",
        "    if drop:\n",
        "        merge_data = merge_data.dropna()\n",
        "    return merge_data"
      ],
      "metadata": {
        "id": "RKS8yoLZovhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###버스정류장 데이터"
      ],
      "metadata": {
        "id": "1fGOFOQqsqcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* 버스정류장 관련 외부 데이터를 활용하여, 하루 배차 회수 1 이하, 정보 누락된 버스정류장 NODE 제외.\n",
        "* plus_grid 함수 사용하여, 그리드 별 개수 COUNT 후 버스 종류인 BRT, 광역, 지선, 간선, 마을 버스를 column으로 지정\n",
        "\n"
      ],
      "metadata": {
        "id": "vxcVWCq4s9OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUS = pd.read_csv(\"busnode.csv\", encoding='utf-8') # 버스정류장 데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "TIME=pd.read_csv(\"time.csv\", encoding='utf-8') # 버스 종류별 배차 횟수 데이터버스 종류별 배차 횟수 데이터\n",
        "\n",
        "BUS=BUS.dropna(how=\"all\")\n",
        "\n",
        "#'정류장번호 없음'은 삭제함.\n",
        "index1=BUS[BUS['NODENO']==\"정류장번호 없음\"].index\n",
        "BUS=BUS.drop(index1)\n",
        "# 정류장 번호 '0'은 삭제함\n",
        "index2=BUS[BUS['NODENO']==\"0\"].index\n",
        "BUS=BUS.drop(index2)\n",
        "# index 새롭게 지정\n",
        "BUS=BUS.reset_index()\n",
        "\n",
        "for i in range(0,len(TIME)): # 버스에 따라, 배차 횟수를 hap이라는 열에 지정.\n",
        "    for j in range(0,len(BUS)) :\n",
        "        if BUS['BUS_NUM'][j] == TIME['버스이름'][i]:\n",
        "            BUS['hap'][j] = TIME['개수'][i]\n",
        "\n",
        "# PCA를 통해, 지수를 생성할 것인데 이때의 변수를 버스 종류로 할 것이기에\n",
        "# BUS 데이터에 빈 열을 생성해주었다.\n",
        "BUS['BRT']=\"\"\n",
        "BUS['광역버스']=\"\"\n",
        "BUS['지선버스']=\"\"\n",
        "BUS['간선버스']=\"\"\n",
        "BUS['마을버스']=\"\"\n",
        "\n",
        "BRT=np.array(['B2','900','B5'],dtype=object)\n",
        "광역버스=np.array(['1000','1001','1004','1005'],dtype=object)\n",
        "지선버스=np.array(['11','12','13','52','53','61','201','203','221','300','910'],dtype=object)\n",
        "간선버스=np.array(['430','991'],dtype=object)\n",
        "마을버스=np.array(['16','17','31','32','33','35','62','63','64','65','66','661','67','69','691','71','72','73','74','75','76','81','82','83','84','85','86','91','92','93','94','95'],dtype=object)\n",
        "\n",
        "for i in range(0,len(BUS)):\n",
        "    if BUS[\"BUS_NUM\"][i] in BRT:\n",
        "        BUS['BRT'][i]=BUS['hap'][i]\n",
        "    elif BUS[\"BUS_NUM\"][i] in 광역버스:\n",
        "        BUS['광역버스'][i]=BUS['hap'][i]\n",
        "    elif BUS[\"BUS_NUM\"][i] in 지선버스:\n",
        "        BUS['지선버스'][i]=BUS['hap'][i]\n",
        "    elif BUS[\"BUS_NUM\"][i] in 간선버스:\n",
        "        BUS['간선버스'][i]=BUS['hap'][i]\n",
        "    elif BUS[\"BUS_NUM\"][i] in 마을버스:\n",
        "        BUS['마을버스'][i]=BUS['hap'][i]\n",
        "    else:\n",
        "        print(\"잘못됨\")\n",
        "\n",
        "BUS=BUS[['NODENO','GPSLATI','GPSLONG','BRT','광역버스','지선버스','간선버스','마을버스']]\n",
        "\n",
        "# gpslong 열에 ,가 한 데이터에 포함되어있어 삭제함.\n",
        "BUS['GPSLONG']=BUS['GPSLONG'].astype(str)\n",
        "BUS['GPSLONG'] = BUS['GPSLONG'].str.replace(',', '').astype('float64')\n",
        "\n",
        "# groupby 함수 사용 위해 float으로 변환.\n",
        "BUS['NODENO']=BUS['NODENO'].apply(pd.to_numeric)\n",
        "BUS['GPSLATI']=BUS['GPSLATI'].apply(pd.to_numeric)\n",
        "BUS['GPSLONG']=BUS['GPSLONG'].apply(pd.to_numeric)\n",
        "BUS['BRT']=BUS['BRT'].apply(pd.to_numeric)\n",
        "BUS['광역버스']=BUS['광역버스'].apply(pd.to_numeric)\n",
        "BUS['지선버스']=BUS['지선버스'].apply(pd.to_numeric)\n",
        "BUS['간선버스']=BUS['간선버스'].apply(pd.to_numeric)\n",
        "BUS['마을버스']=BUS['마을버스'].apply(pd.to_numeric)\n",
        "\n",
        "# 버스정류장번호(NODENO)별 \n",
        "BUS1=BUS.groupby([\"NODENO\",\"GPSLATI\",\"GPSLONG\"])['BRT','광역버스','지선버스','간선버스','마을버스'].sum().reset_index()\n",
        "\n",
        "# NODENO는 같지만, GPSLATI와 GPSLONG이 다른 데이터 존재.\n",
        "BUS1=BUS1.drop_duplicates(['NODENO'], keep=False)"
      ],
      "metadata": {
        "id": "fKmOtEOws8PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bus = plus_grid(BUS1, geo, 'GPSLONG', 'GPSLATI')"
      ],
      "metadata": {
        "id": "9xcAMadPtN5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CCTV 데이터"
      ],
      "metadata": {
        "id": "TPcfkthhtOu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('cctv.csv') # CCTV 데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "# CCTV 데이터에서 필요한 컬럼만 추출\n",
        "df = df[['카메라대수','카메라화소수','위도','경도']]\n",
        "\n",
        "cctv = plus_grid(df, geo, '경도', '위도')"
      ],
      "metadata": {
        "id": "-spDsQcYtTZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###가로등 데이터"
      ],
      "metadata": {
        "id": "oCrbjD8GtXQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('light.csv') # 가로등 데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "# 가로등 데이터에서 필요한 컬럼만 추출\n",
        "df = df[['가로등위치명','소재지지번주소','위도','경도']]\n",
        "\n",
        "street_lights = plus_grid(df, geo, '경도', '위도')"
      ],
      "metadata": {
        "id": "lBw5K1dvta_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###파출소 데이터"
      ],
      "metadata": {
        "id": "2JDD4dJUtc51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('policeoffice.csv') # 파출소 데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "# Hospital 데이터에서 필요한 컬럼만 추출\n",
        "df = df[['name','입력주소','X','Y']]\n",
        "\n",
        "police_office = plus_grid(df, geo, 'X', 'Y')"
      ],
      "metadata": {
        "id": "AVUY6jyotfh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###학교 데이터"
      ],
      "metadata": {
        "id": "cgpjGEsJthvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('school.csv') # 학교 데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "# 학교 데이터에서 필요한 컬럼만 추출\n",
        "df = df[['학교명','학교구분','주소','X','Y']]\n",
        "\n",
        "school = plus_grid(df, geo, 'X', 'Y')"
      ],
      "metadata": {
        "id": "ghvjqvRAtj9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###공원 데이터"
      ],
      "metadata": {
        "id": "M3IdXz97toTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('park.csv') #공원데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "# 공원 데이터에서 필요한 컬럼만 추출\n",
        "df = df[['공원명','소재지지번주소','공원구분','위도','경도']]\n",
        "\n",
        "parks = plus_grid(df, geo, '경도', '위도')"
      ],
      "metadata": {
        "id": "mGXA0xoCtrUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###학원 데이터"
      ],
      "metadata": {
        "id": "geJ7jQyItt5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 불러옵니다\n",
        "df = pd.read_csv('academy.csv') #학원데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "# 학원 데이터에서 필요한 컬럼만 추출\n",
        "academy1 = df[['학원주소','X','Y']]\n",
        "\n",
        "# 상권 데이터에서 학원 데이터를 추출합니다\n",
        "academy2 = data14[data14['상권업종중분류명'].str.contains('학원')]\n",
        "academy2 = academy2.rename({'lon':'X', 'lat':'Y', '도로명주소':'학원주소'}, axis='columns')\n",
        "academy_cat = ['학원(종합)','학원-입시','학원-외국어/어학','학원-어린이영어','태권도장', '피아노/바이올린/기타','합기도장','서예/서화/미술']\n",
        "academy2 = academy2[academy2.상권업종소분류명.isin(academy_cat)][['학원주소','X', 'Y']]\n",
        "\n",
        "# 두 데이터를 합쳐줍니다\n",
        "df = pd.merge(academy1, academy2, on=['X','Y','학원주소'], how='outer')\n",
        "\n",
        "academy = plus_grid(df, geo, 'X', 'Y')"
      ],
      "metadata": {
        "id": "RF9ITrpptyOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###편의점 데이터"
      ],
      "metadata": {
        "id": "5VwVBw_Ut03c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 불러옵니다\n",
        "df = data14\n",
        "\n",
        "# 편의점 데이터만 추출합니다\n",
        "df = df[df['상권업종소분류명'].str.contains('편의점')]\n",
        "df = df[['행정동명','도로명주소','lon','lat']]\n",
        "\n",
        "# 편의점 데이터를 격자 데이터에 부여\n",
        "stores = plus_grid(df, geo, 'lon', 'lat')"
      ],
      "metadata": {
        "id": "lfiqSehFt20h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###은행 데이터"
      ],
      "metadata": {
        "id": "PQsKGeYXt4py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('bank.csv') #은행데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "df = df[['name', 'address', '경도','위도']]\n",
        "\n",
        "# 은행 데이터를 격자 데이터에 부여\n",
        "banks = plus_grid(df, geo, '경도', '위도')"
      ],
      "metadata": {
        "id": "UUQ_sUGXuAFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###약국 데이터"
      ],
      "metadata": {
        "id": "6XzeXjdruDJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('pharmacy.csv') #약국데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "df = df[['_약국명칭', '약국소재지 도로명주소', 'X','Y']]\n",
        "\n",
        "# 약국 데이터를 격자 데이터에 부여\n",
        "pharmacy = plus_grid(df, geo, 'X', 'Y')"
      ],
      "metadata": {
        "id": "Qu24pl52uGSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###마트 데이터"
      ],
      "metadata": {
        "id": "4CSNlSXzuIWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('market.csv') #약국데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "df = df[['name', 'address', 'X','Y']]\n",
        "\n",
        "# 약국 데이터를 격자 데이터에 부여\n",
        "mart = plus_grid(df, geo, 'X', 'Y')"
      ],
      "metadata": {
        "id": "3tbwK8EhuJ6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###병원 데이터"
      ],
      "metadata": {
        "id": "aANfnPwmuN18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('hospital.csv') # 병원 데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "# Hospital 데이터에서 필요한 컬럼만 추출\n",
        "df = df[['name','입력주소','X','Y']]\n",
        "\n",
        "hospital= plus_grid(df, geo, 'X', 'Y')"
      ],
      "metadata": {
        "id": "_5pjq1rTuPcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###매매 데이터"
      ],
      "metadata": {
        "id": "wdnlzCKYuRa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 평당 가격 구하는 함수 정의\n",
        "def price_per(df , col='거래금액(만원)'):\n",
        "    df['평'] = df['전용면적(㎡)']/3.3\n",
        "    df['거래금액'] = df[col].str.replace(',','').astype(int)\n",
        "    df['평당가격'] = df['거래금액']/df['평']\n",
        "    df = df.drop(['평',col], axis=1)\n",
        "    return df\n",
        "\n",
        "# 매매, 전월세 데이터 geocoding 된 데이터\n",
        "adr = pd.read_csv('geoaddress.csv')\n",
        "adr = adr[['입력주소','X','Y']]\n",
        "\n",
        "df3 = price_per(data3)\n",
        "df4 = price_per(data4)\n",
        "df6 = price_per(data6)\n",
        "\n",
        "df3 = pd.merge(get_address(df3)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #아파트 매매 데이터에 위경도 추가\n",
        "apt_buy = plus_grid(df3, geo, 'X','Y', drop=False)\n",
        "\n",
        "df4 = pd.merge(get_address(df4)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #연립다세대 매매 데이터에 위경도 추가\n",
        "vil_buy = plus_grid(df4, geo, 'X','Y', drop=False)\n",
        "\n",
        "df6 = pd.merge(get_address(df6)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #오피스텔 매매 데이터에 위경도 추가\n",
        "ops_buy = plus_grid(df6, geo, 'X','Y', drop=False)"
      ],
      "metadata": {
        "id": "2zGl7GXxuUg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###임대 데이터"
      ],
      "metadata": {
        "id": "f5GdCEYyudKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전월세 데이터를 전세와 월세로 구분합니다\n",
        "# 1이 전세, 2가 월세\n",
        "\n",
        "df71 = data7[data7['전월세구분'] == '전세']\n",
        "df72 = data7[data7['전월세구분'] == '월세']\n",
        "df81 = data8[data8['전월세구분'] == '전세']\n",
        "df82 = data8[data8['전월세구분'] == '월세']\n",
        "df101 = data10[data10['전월세구분'] == '전세']\n",
        "df102 = data10[data10['전월세구분'] == '월세']\n",
        "\n",
        "df71 = price_per(df71, col='보증금(만원)')\n",
        "df81 = price_per(df81, col='보증금(만원)')\n",
        "df101 = price_per(df101, col='보증금(만원)')\n",
        "\n",
        "# 전세 데이터\n",
        "\n",
        "df3 = pd.merge(get_address(df71)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #아파트 매매 데이터에 위경도 추가\n",
        "apt_full = plus_grid(df3, geo, 'X','Y', drop=False)\n",
        "\n",
        "df4 = pd.merge(get_address(df81)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #연립다세대 매매 데이터에 위경도 추가\n",
        "vil_full = plus_grid(df4, geo, 'X','Y', drop=False)\n",
        "\n",
        "df6 = pd.merge(get_address(df101)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #오피스텔 매매 데이터에 위경도 추가\n",
        "ops_full = plus_grid(df6, geo, 'X','Y', drop=False)\n",
        "\n",
        "# 임대(전세+월세) 데이터\n",
        "\n",
        "df3 = pd.merge(get_address(data7)[['계약년월','입력주소','시군구']], adr, on='입력주소') #아파트 매매 데이터에 위경도 추가\n",
        "apt_rent = plus_grid(df3, geo, 'X','Y', drop=False)\n",
        "\n",
        "df4 = pd.merge(get_address(data8)[['계약년월','입력주소','시군구']], adr, on='입력주소') #연립다세대 매매 데이터에 위경도 추가\n",
        "vil_rent = plus_grid(df4, geo, 'X','Y', drop=False)\n",
        "\n",
        "df6 = pd.merge(get_address(data10)[['계약년월','입력주소','시군구']], adr, on='입력주소') #오피스텔 매매 데이터에 위경도 추가\n",
        "ops_rent = plus_grid(df6, geo, 'X','Y', drop=False)"
      ],
      "metadata": {
        "id": "xS3ejeSfueny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###공시지가 데이터"
      ],
      "metadata": {
        "id": "0Wnd6Tc5uukt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('zin18.csv') #Geocoding 데이터\n",
        "df = pd.merge(houseonly, df, left_on = '대지위치', right_on = '지번주소') # 공시지가 데이터\n",
        "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
        "\n",
        "df = df[['건물명', '지번주소','기준년도','공시지가', 'X','Y']]\n",
        "\n",
        "# 공시지가 데이터를 격자 데이터에 부여\n",
        "gongsi = plus_grid(df, geo, 'X', 'Y', drop=False)"
      ],
      "metadata": {
        "id": "CRTHz-yquweM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###표재부 주택 데이터"
      ],
      "metadata": {
        "id": "FLpy9QELuzOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Geocoding된 주택 데이터\n",
        "res = pd.concat([pd.read_csv('houseadd_file1.csv'), pd.read_csv('houseadd_file2.csv')])\n",
        "\n",
        "# 주택 데이터를 격자 데이터에 부여\n",
        "reals = plus_grid(res, geo, 'X', 'Y')"
      ],
      "metadata": {
        "id": "C0Bs59kdu1vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###인구 데이터"
      ],
      "metadata": {
        "id": "R_qXJBIuu4WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#거주인구정보 500미터 격자 파일과 합치기\n",
        "grid_500 = geo[['id', 'geometry']]\n",
        "merge19 = gpd.sjoin(grid_500, data19, op='intersects', how = 'left').reset_index()\n",
        "\n",
        "# 중복 제거해주기\n",
        "dropdu = merge19[['gid','201710_20대_거주인구수']].drop_duplicates().index\n",
        "merge19 = merge19.loc[dropdu,:]\n",
        "merge19_group = merge19.groupby('id').sum().reset_index()\n",
        "population = merge19_group"
      ],
      "metadata": {
        "id": "U-rxONTlu6Cj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}